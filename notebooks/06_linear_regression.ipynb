{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using these data paths:\n",
      "X_train: ../data/processed/X_train.parquet\n",
      "X_test : ../data/processed/X_test.parquet\n",
      "y_train: ../data/processed/y_train.parquet\n",
      "y_test : ../data/processed/y_test.parquet\n",
      "\n",
      "Shapes:\n",
      "X_train: (1568133, 57)\n",
      "X_test : (392034, 57)\n",
      "y_train: (1568133,)\n",
      "y_test : (392034,)\n",
      "\n",
      "Training completed in 2.41 seconds.\n",
      "Predictions saved to: ../output/linear_regression_predictions.csv\n",
      "\n",
      "=== Linear Regression Performance ===\n",
      "\n",
      "TRAIN METRICS:\n",
      "  RMSE : 5.3076\n",
      "  MAE  : 2.1167\n",
      "  MAPE : 21.45%\n",
      "  R^2  : 0.9101\n",
      "  RMSLE: 0.1882\n",
      "\n",
      "TEST METRICS:\n",
      "  RMSE : 12.5087\n",
      "  MAE  : 2.1964\n",
      "  MAPE : 18.63%\n",
      "  R^2  : 0.3874\n",
      "  RMSLE: 0.1909\n",
      "\n",
      "=== Residual Analysis (Test) ===\n",
      "Mean residual      : 0.1608\n",
      "Std of residuals   : 12.5077\n",
      "Min residual       : -7279.0647\n",
      "Max residual       : 348.5867\n",
      "Residual plots saved to:\n",
      "  Histogram : ../output/linear_regression_residuals_hist.png\n",
      "  Res vs Pred: ../output/linear_regression_residuals_vs_pred.png\n",
      "Coefficient table saved to: ../output/linear_regression_coefficients.csv\n",
      "Intercept: 18.0439\n",
      "Top-15 feature importance plot saved to: ../output/linear_regression_top_features.png\n",
      "\n",
      "=== Overfitting Check ===\n",
      "Train RMSE: 5.3076, Test RMSE: 12.5087\n",
      "Train R^2 : 0.9101, Test R^2 : 0.3874\n",
      "\n",
      "Model saved to: ../models/linear_regression_model.pkl\n",
      "Actual vs predicted plot saved to: ../output/linear_regression_actual_vs_pred.png\n",
      "\n",
      "Top 20 largest absolute prediction errors (test):\n",
      "        actual    predicted    abs_error\n",
      "256200  169.60  7448.664692  7279.064692\n",
      "157588  370.00    21.413288   348.586712\n",
      "383666  380.00    34.930915   345.069085\n",
      "115170  300.00    12.288091   287.711909\n",
      "292541  300.00   567.318172   267.318172\n",
      "281728  495.10   250.238503   244.861497\n",
      "311603  518.20   305.317915   212.882085\n",
      "261924  210.00    14.258991   195.741009\n",
      "177607  200.00     7.483262   192.516738\n",
      "6036    400.00   224.808772   175.191228\n",
      "47211   399.90   226.911435   172.988565\n",
      "303014  450.00   278.732848   171.267152\n",
      "357813  191.01    20.802830   170.207170\n",
      "17123   180.00    13.119541   166.880459\n",
      "250654  350.00   189.503277   160.496723\n",
      "346492  160.00     5.161069   154.838931\n",
      "268063  160.00     5.910404   154.089596\n",
      "103110  159.00    10.187421   148.812579\n",
      "324960  180.00    33.441307   146.558693\n",
      "158013  150.00     6.887254   143.112746\n",
      "\n",
      "Absolute error by fare range (test):\n",
      "                 mean    median   count\n",
      "fare_range                             \n",
      "0-10         1.681846  1.622641  137254\n",
      "10-20        1.387317  1.057971  161338\n",
      "20-40        3.227002  2.646592   61267\n",
      "40-80        5.289847  2.824494   29922\n",
      "80+         22.378732  4.608466    2253\n",
      "\n",
      "Evaluation report saved to: ../output/linear_regression_evaluation.txt\n",
      "\n",
      " Linear Regression training & evaluation completed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/c_/mhx6w8j52_d7vbz5h9bq_djc0000gn/T/ipykernel_16831/1768095211.py:275: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  range_stats = test_pred_df.groupby(\"fare_range\")[\"abs_error\"].agg([\"mean\", \"median\", \"count\"])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# ============================================================\n",
    "# 0. PATH SETUP\n",
    "# ============================================================\n",
    "# Data base\n",
    "if os.path.isdir(\"/data\"):\n",
    "    DATA_BASE = \"/data\"\n",
    "else:\n",
    "    DATA_BASE = \"../data\"\n",
    "\n",
    "PROCESSED_DIR = os.path.join(DATA_BASE, \"processed\")\n",
    "os.makedirs(PROCESSED_DIR, exist_ok=True)\n",
    "\n",
    "\n",
    "if os.path.isdir(\"/models\"):\n",
    "    MODELS_DIR = \"/models\"\n",
    "else:\n",
    "    MODELS_DIR = \"../models\"\n",
    "os.makedirs(MODELS_DIR, exist_ok=True)\n",
    "\n",
    "\n",
    "if os.path.isdir(\"/output\"):\n",
    "    OUTPUT_DIR = \"/output\"\n",
    "else:\n",
    "    OUTPUT_DIR = \"../output\"\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "def pick_path(filename_sample, filename_full):\n",
    "    sample_path = os.path.join(PROCESSED_DIR, filename_sample)\n",
    "    full_path   = os.path.join(PROCESSED_DIR, filename_full)\n",
    "    if os.path.exists(sample_path):\n",
    "        return sample_path\n",
    "    return full_path\n",
    "\n",
    "X_train_path = pick_path(\"X_train_sample.parquet\", \"X_train.parquet\")\n",
    "X_test_path  = pick_path(\"X_test_sample.parquet\",  \"X_test.parquet\")\n",
    "y_train_path = pick_path(\"y_train_sample.parquet\", \"y_train.parquet\")\n",
    "y_test_path  = pick_path(\"y_test_sample.parquet\",  \"y_test.parquet\")\n",
    "\n",
    "print(\"Using these data paths:\")\n",
    "print(\"X_train:\", X_train_path)\n",
    "print(\"X_test :\", X_test_path)\n",
    "print(\"y_train:\", y_train_path)\n",
    "print(\"y_test :\", y_test_path)\n",
    "\n",
    "coefficients_out_path = os.path.join(OUTPUT_DIR, \"linear_regression_coefficients.csv\")\n",
    "predictions_out_path  = os.path.join(OUTPUT_DIR, \"linear_regression_predictions.csv\")\n",
    "evaluation_out_path   = os.path.join(OUTPUT_DIR, \"linear_regression_evaluation.txt\")\n",
    "model_out_path        = os.path.join(MODELS_DIR, \"linear_regression_model.pkl\")\n",
    "\n",
    "residual_hist_path    = os.path.join(OUTPUT_DIR, \"linear_regression_residuals_hist.png\")\n",
    "residual_vs_pred_path = os.path.join(OUTPUT_DIR, \"linear_regression_residuals_vs_pred.png\")\n",
    "actual_vs_pred_path   = os.path.join(OUTPUT_DIR, \"linear_regression_actual_vs_pred.png\")\n",
    "\n",
    "# ============================================================\n",
    "# 1. LOAD TRAIN/TEST DATA\n",
    "# ============================================================\n",
    "X_train = pd.read_parquet(X_train_path)\n",
    "X_test  = pd.read_parquet(X_test_path)\n",
    "\n",
    "y_train_df = pd.read_parquet(y_train_path)\n",
    "y_test_df  = pd.read_parquet(y_test_path)\n",
    "\n",
    "y_train = y_train_df.iloc[:, 0]\n",
    "y_test  = y_test_df.iloc[:, 0]\n",
    "\n",
    "print(\"\\nShapes:\")\n",
    "print(\"X_train:\", X_train.shape)\n",
    "print(\"X_test :\", X_test.shape)\n",
    "print(\"y_train:\", y_train.shape)\n",
    "print(\"y_test :\", y_test.shape)\n",
    "\n",
    "feature_names = X_train.columns.tolist()\n",
    "\n",
    "# ============================================================\n",
    "# 2. MODEL INITIALIZATION & TRAINING\n",
    "# ============================================================\n",
    "model = LinearRegression()\n",
    "\n",
    "start_time = time.time()\n",
    "model.fit(X_train, y_train)\n",
    "train_duration = time.time() - start_time\n",
    "\n",
    "print(f\"\\nTraining completed in {train_duration:.2f} seconds.\")\n",
    "\n",
    "# ============================================================\n",
    "# 3. PREDICTIONS\n",
    "# ============================================================\n",
    "y_pred_train = model.predict(X_train)\n",
    "y_pred_test  = model.predict(X_test)\n",
    "\n",
    "pred_df = pd.DataFrame({\n",
    "    \"set\":      [\"train\"] * len(y_train) + [\"test\"] * len(y_test),\n",
    "    \"actual\":   pd.concat([y_train, y_test], ignore_index=True),\n",
    "    \"predicted\": np.concatenate([y_pred_train, y_pred_test])\n",
    "})\n",
    "pred_df.to_csv(predictions_out_path, index=False)\n",
    "print(\"Predictions saved to:\", predictions_out_path)\n",
    "\n",
    "# ============================================================\n",
    "# 4. METRICS FUNCTIONS\n",
    "# ============================================================\n",
    "def rmse(y_true, y_pred):\n",
    "    return np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "\n",
    "def mae(y_true, y_pred):\n",
    "    return mean_absolute_error(y_true, y_pred)\n",
    "\n",
    "def mape(y_true, y_pred):\n",
    "    y_true = np.asarray(y_true)\n",
    "    y_pred = np.asarray(y_pred)\n",
    "    mask = y_true != 0\n",
    "    if mask.sum() == 0:\n",
    "        return np.nan\n",
    "    return np.mean(np.abs((y_true[mask] - y_pred[mask]) / y_true[mask])) * 100.0\n",
    "\n",
    "def rmsle(y_true, y_pred):\n",
    "    y_true = np.asarray(y_true)\n",
    "    y_pred = np.asarray(y_pred)\n",
    "    y_true_clipped = np.clip(y_true, a_min=0, a_max=None)\n",
    "    y_pred_clipped = np.clip(y_pred, a_min=0, a_max=None)\n",
    "    return np.sqrt(\n",
    "        np.mean(\n",
    "            (np.log1p(y_true_clipped) - np.log1p(y_pred_clipped)) ** 2\n",
    "        )\n",
    "    )\n",
    "\n",
    "# ============================================================\n",
    "# 5. MODEL EVALUATION (TRAIN & TEST)\n",
    "# ============================================================\n",
    "metrics = {}\n",
    "\n",
    "for split_name, y_true, y_pred in [\n",
    "    (\"train\", y_train, y_pred_train),\n",
    "    (\"test\",  y_test,  y_pred_test),\n",
    "]:\n",
    "    split_metrics = {\n",
    "        \"RMSE\":  rmse(y_true, y_pred),\n",
    "        \"MAE\":   mae(y_true, y_pred),\n",
    "        \"MAPE\":  mape(y_true, y_pred),\n",
    "        \"R2\":    r2_score(y_true, y_pred),\n",
    "        \"RMSLE\": rmsle(y_true, y_pred),\n",
    "    }\n",
    "    metrics[split_name] = split_metrics\n",
    "\n",
    "print(\"\\n=== Linear Regression Performance ===\")\n",
    "for split_name in [\"train\", \"test\"]:\n",
    "    m = metrics[split_name]\n",
    "    print(f\"\\n{split_name.upper()} METRICS:\")\n",
    "    print(f\"  RMSE : {m['RMSE']:.4f}\")\n",
    "    print(f\"  MAE  : {m['MAE']:.4f}\")\n",
    "    print(f\"  MAPE : {m['MAPE']:.2f}%\")\n",
    "    print(f\"  R^2  : {m['R2']:.4f}\")\n",
    "    print(f\"  RMSLE: {m['RMSLE']:.4f}\")\n",
    "\n",
    "# ============================================================\n",
    "# 6. RESIDUAL ANALYSIS (TEST SET)\n",
    "# ============================================================\n",
    "residuals = y_test - y_pred_test\n",
    "\n",
    "res_mean = residuals.mean()\n",
    "res_std  = residuals.std()\n",
    "res_min  = residuals.min()\n",
    "res_max  = residuals.max()\n",
    "\n",
    "print(\"\\n=== Residual Analysis (Test) ===\")\n",
    "print(f\"Mean residual      : {res_mean:.4f}\")\n",
    "print(f\"Std of residuals   : {res_std:.4f}\")\n",
    "print(f\"Min residual       : {res_min:.4f}\")\n",
    "print(f\"Max residual       : {res_max:.4f}\")\n",
    "\n",
    "# Residual distribution plot\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.hist(residuals, bins=80, alpha=0.7)\n",
    "plt.title(\"Residual Distribution (Test)\")\n",
    "plt.xlabel(\"Residual (actual - predicted)\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(residual_hist_path)\n",
    "plt.close()\n",
    "\n",
    "# Residuals vs predicted values\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.scatter(y_pred_test, residuals, s=5)\n",
    "plt.axhline(0, linestyle=\"--\")\n",
    "plt.title(\"Residuals vs Predicted (Test)\")\n",
    "plt.xlabel(\"Predicted fare_amount\")\n",
    "plt.ylabel(\"Residual (actual - predicted)\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(residual_vs_pred_path)\n",
    "plt.close()\n",
    "\n",
    "print(\"Residual plots saved to:\")\n",
    "print(\"  Histogram :\", residual_hist_path)\n",
    "print(\"  Res vs Pred:\", residual_vs_pred_path)\n",
    "\n",
    "# ============================================================\n",
    "# 7. MODEL COEFFICIENTS / FEATURE IMPORTANCE\n",
    "# ============================================================\n",
    "coefs = model.coef_\n",
    "intercept = model.intercept_\n",
    "\n",
    "coef_df = pd.DataFrame({\n",
    "    \"feature\": feature_names,\n",
    "    \"coefficient\": coefs,\n",
    "    \"abs_coefficient\": np.abs(coefs),\n",
    "}).sort_values(\"abs_coefficient\", ascending=False)\n",
    "\n",
    "coef_df.to_csv(coefficients_out_path, index=False)\n",
    "print(\"Coefficient table saved to:\", coefficients_out_path)\n",
    "print(f\"Intercept: {intercept:.4f}\")\n",
    "\n",
    "top_n = 15\n",
    "top_coef = coef_df.head(top_n)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.barh(top_coef[\"feature\"][::-1], top_coef[\"coefficient\"][::-1])\n",
    "plt.title(\"Top 15 Features by Coefficient Magnitude (Linear Regression)\")\n",
    "plt.xlabel(\"Coefficient value\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(OUTPUT_DIR, \"linear_regression_top_features.png\"))\n",
    "plt.close()\n",
    "\n",
    "print(\"Top-15 feature importance plot saved to:\",\n",
    "      os.path.join(OUTPUT_DIR, \"linear_regression_top_features.png\"))\n",
    "\n",
    "# ============================================================\n",
    "# 8. OVERFITTING CHECK\n",
    "# ============================================================\n",
    "train_rmse = metrics[\"train\"][\"RMSE\"]\n",
    "test_rmse  = metrics[\"test\"][\"RMSE\"]\n",
    "train_r2   = metrics[\"train\"][\"R2\"]\n",
    "test_r2    = metrics[\"test\"][\"R2\"]\n",
    "\n",
    "print(\"\\n=== Overfitting Check ===\")\n",
    "print(f\"Train RMSE: {train_rmse:.4f}, Test RMSE: {test_rmse:.4f}\")\n",
    "print(f\"Train R^2 : {train_r2:.4f}, Test R^2 : {test_r2:.4f}\")\n",
    "\n",
    "# ============================================================\n",
    "# 9. SAVE MODEL\n",
    "# ============================================================\n",
    "joblib.dump(model, model_out_path)\n",
    "print(\"\\nModel saved to:\", model_out_path)\n",
    "\n",
    "# ============================================================\n",
    "# 10. PREDICTIONS ANALYSIS (TEST SET)\n",
    "# ============================================================\n",
    "test_pred_df = pd.DataFrame({\n",
    "    \"actual\":    y_test.values,\n",
    "    \"predicted\": y_pred_test,\n",
    "})\n",
    "test_pred_df[\"abs_error\"] = np.abs(test_pred_df[\"actual\"] - test_pred_df[\"predicted\"])\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.scatter(test_pred_df[\"actual\"], test_pred_df[\"predicted\"], s=5)\n",
    "min_val = min(test_pred_df[\"actual\"].min(), test_pred_df[\"predicted\"].min())\n",
    "max_val = max(test_pred_df[\"actual\"].max(), test_pred_df[\"predicted\"].max())\n",
    "plt.plot([min_val, max_val], [min_val, max_val], linestyle=\"--\")\n",
    "plt.title(\"Actual vs Predicted Fare (Test)\")\n",
    "plt.xlabel(\"Actual fare_amount\")\n",
    "plt.ylabel(\"Predicted fare_amount\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(actual_vs_pred_path)\n",
    "plt.close()\n",
    "\n",
    "print(\"Actual vs predicted plot saved to:\", actual_vs_pred_path)\n",
    "\n",
    "largest_errors = test_pred_df.sort_values(\"abs_error\", ascending=False).head(20)\n",
    "print(\"\\nTop 20 largest absolute prediction errors (test):\")\n",
    "print(largest_errors)\n",
    "\n",
    "bins = [0, 10, 20, 40, 80, np.inf]\n",
    "labels = [\"0-10\", \"10-20\", \"20-40\", \"40-80\", \"80+\"]\n",
    "\n",
    "test_pred_df[\"fare_range\"] = pd.cut(test_pred_df[\"actual\"], bins=bins, labels=labels)\n",
    "range_stats = test_pred_df.groupby(\"fare_range\")[\"abs_error\"].agg([\"mean\", \"median\", \"count\"])\n",
    "print(\"\\nAbsolute error by fare range (test):\")\n",
    "print(range_stats)\n",
    "\n",
    "# ============================================================\n",
    "# 11. PERFORMANCE REPORT (TEXT FILE)\n",
    "# ============================================================\n",
    "with open(evaluation_out_path, \"w\") as f:\n",
    "    f.write(\"Linear Regression Model â€“ Fare Prediction\\n\")\n",
    "    f.write(\"=========================================\\n\\n\")\n",
    "    f.write(f\"Training duration: {train_duration:.2f} seconds\\n\\n\")\n",
    "\n",
    "    for split_name in [\"train\", \"test\"]:\n",
    "        m = metrics[split_name]\n",
    "        f.write(f\"{split_name.upper()} METRICS:\\n\")\n",
    "        f.write(f\"  RMSE : {m['RMSE']:.4f}\\n\")\n",
    "        f.write(f\"  MAE  : {m['MAE']:.4f}\\n\")\n",
    "        f.write(f\"  MAPE : {m['MAPE']:.2f}%\\n\")\n",
    "        f.write(f\"  R^2  : {m['R2']:.4f}\\n\")\n",
    "        f.write(f\"  RMSLE: {m['RMSLE']:.4f}\\n\\n\")\n",
    "\n",
    "    f.write(\"Overfitting check:\\n\")\n",
    "    f.write(f\"  Train RMSE: {train_rmse:.4f}, Test RMSE: {test_rmse:.4f}\\n\")\n",
    "    f.write(f\"  Train R^2 : {train_r2:.4f}, Test R^2 : {test_r2:.4f}\\n\\n\")\n",
    "\n",
    "    f.write(\"Residual analysis (test):\\n\")\n",
    "    f.write(f\"  Mean residual    : {res_mean:.4f}\\n\")\n",
    "    f.write(f\"  Std residual     : {res_std:.4f}\\n\")\n",
    "    f.write(f\"  Min residual     : {res_min:.4f}\\n\")\n",
    "    f.write(f\"  Max residual     : {res_max:.4f}\\n\\n\")\n",
    "\n",
    "    f.write(\"Top 15 features by |coefficient|:\\n\")\n",
    "    for _, row in top_coef.iterrows():\n",
    "        f.write(f\"  {row['feature']}: coef={row['coefficient']:.6f}, \"\n",
    "                f\"|coef|={row['abs_coefficient']:.6f}\\n\")\n",
    "\n",
    "    f.write(\"\\nAbsolute error by fare range (test):\\n\")\n",
    "    f.write(range_stats.to_string())\n",
    "    f.write(\"\\n\")\n",
    "\n",
    "print(\"\\nEvaluation report saved to:\", evaluation_out_path)\n",
    "print(\"\\n Linear Regression training & evaluation completed.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
