{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged input      : ../data/processed/taxi_weather_zones_merged_2023_sample.parquet\n",
      "Engineered output : ../data/processed/engineered_features_2023_sample.parquet\n",
      "\n",
      "=== Loaded merged dataset ===\n",
      "(1960211, 29)\n",
      "   VendorID tpep_pickup_datetime tpep_dropoff_datetime  passenger_count  \\\n",
      "0         2  2023-01-01 00:32:10   2023-01-01 00:40:36              1.0   \n",
      "1         2  2023-01-01 00:55:08   2023-01-01 01:01:27              1.0   \n",
      "2         2  2023-01-01 00:25:04   2023-01-01 00:37:49              1.0   \n",
      "3         1  2023-01-01 00:03:48   2023-01-01 00:13:25              0.0   \n",
      "4         2  2023-01-01 00:10:29   2023-01-01 00:21:19              1.0   \n",
      "\n",
      "   trip_distance  RatecodeID store_and_fwd_flag  PULocationID  DOLocationID  \\\n",
      "0           0.97         1.0                  N           161           141   \n",
      "1           1.10         1.0                  N            43           237   \n",
      "2           2.51         1.0                  N            48           238   \n",
      "3           1.90         1.0                  N           138             7   \n",
      "4           1.43         1.0                  N           107            79   \n",
      "\n",
      "   payment_type  ...  Airport_fee  pickup_date  pickup_borough  \\\n",
      "0             2  ...          NaN   2023-01-01       Manhattan   \n",
      "1             1  ...          NaN   2023-01-01       Manhattan   \n",
      "2             1  ...          NaN   2023-01-01       Manhattan   \n",
      "3             1  ...          NaN   2023-01-01          Queens   \n",
      "4             1  ...          NaN   2023-01-01       Manhattan   \n",
      "\n",
      "         pickup_zone  temperature_avg  precipitation  is_raining  \\\n",
      "0     Midtown Center             51.1       0.286667         1.0   \n",
      "1       Central Park             51.1       0.286667         1.0   \n",
      "2       Clinton East             51.1       0.286667         1.0   \n",
      "3  LaGuardia Airport             51.1       0.286667         1.0   \n",
      "4           Gramercy             51.1       0.286667         1.0   \n",
      "\n",
      "   temp_category  dropoff_borough           dropoff_zone  \n",
      "0         normal        Manhattan        Lenox Hill West  \n",
      "1         normal        Manhattan  Upper East Side South  \n",
      "2         normal        Manhattan  Upper West Side North  \n",
      "3         normal           Queens                Astoria  \n",
      "4         normal        Manhattan           East Village  \n",
      "\n",
      "[5 rows x 29 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/c_/mhx6w8j52_d7vbz5h9bq_djc0000gn/T/ipykernel_19289/753150083.py:205: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(df[col].mean(), inplace=True)\n",
      "/var/folders/c_/mhx6w8j52_d7vbz5h9bq_djc0000gn/T/ipykernel_19289/753150083.py:208: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(df[col].mode()[0], inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dropping target/financial-leaking features from engineered dataset used for modeling:\n",
      "['fare_per_mile', 'fare_per_minute', 'fare_per_distance_per_minute', 'extreme_fare_flag', 'zero_fare_flag', 'total_amount', 'tip_amount', 'tolls_amount', 'mta_tax', 'extra', 'congestion_surcharge', 'airport_fee']\n",
      "\n",
      " Saved engineered dataset to: ../data/processed/engineered_features_2023_sample.parquet\n",
      " Saved feature list: ../data/processed/feature_list_sample.txt\n",
      " Saved feature statistics: ../data/processed/feature_statistics_sample.csv\n",
      "\n",
      "=== FINAL SUMMARY ===\n",
      "Total rows  : 1960167\n",
      "Total cols  : 54\n",
      "Numerical   : 36\n",
      "Categorical : 10\n",
      "\n",
      "Missing values per feature:\n",
      "Airport_fee                 1960167\n",
      "VendorID                          0\n",
      "hourly_pickup_count               0\n",
      "trip_duration_minutes             0\n",
      "avg_speed_mph                     0\n",
      "distance_squared                  0\n",
      "duration_squared                  0\n",
      "temp_fahrenheit                   0\n",
      "temp_deviation                    0\n",
      "extreme_weather                   0\n",
      "same_borough                      0\n",
      "zone_pair_encoded                 0\n",
      "pickup_density                    0\n",
      "traffic_volume_category           0\n",
      "zone_hourly_pickup_count          0\n",
      "quarter                           0\n",
      "is_peak_hour                      0\n",
      "is_late_night                     0\n",
      "surge_likelihood                  0\n",
      "trip_complexity                   0\n",
      "dtype: int64\n",
      "\n",
      "Sample of engineered data:\n",
      "   VendorID tpep_pickup_datetime tpep_dropoff_datetime  passenger_count  \\\n",
      "0         2  2023-01-01 00:32:10   2023-01-01 00:40:36              1.0   \n",
      "1         2  2023-01-01 00:55:08   2023-01-01 01:01:27              1.0   \n",
      "2         2  2023-01-01 00:25:04   2023-01-01 00:37:49              1.0   \n",
      "3         1  2023-01-01 00:03:48   2023-01-01 00:13:25              0.0   \n",
      "4         2  2023-01-01 00:10:29   2023-01-01 00:21:19              1.0   \n",
      "\n",
      "   trip_distance  RatecodeID store_and_fwd_flag  PULocationID  DOLocationID  \\\n",
      "0           0.97         1.0                  N           161           141   \n",
      "1           1.10         1.0                  N            43           237   \n",
      "2           2.51         1.0                  N            48           238   \n",
      "3           1.90         1.0                  N           138             7   \n",
      "4           1.43         1.0                  N           107            79   \n",
      "\n",
      "   payment_type  ...  is_late_night  surge_likelihood  trip_complexity  \\\n",
      "0             2  ...              1          1.387485         6.694150   \n",
      "1             1  ...              1          1.387485        11.493404   \n",
      "2             1  ...              1          1.387485        29.647529   \n",
      "3             1  ...              1          1.387485        22.523397   \n",
      "4             1  ...              1          1.387485        11.325600   \n",
      "\n",
      "  time_of_day_factor day_type extreme_distance_flag  zero_distance_flag  \\\n",
      "0              night  holiday                     0                   0   \n",
      "1              night  holiday                     0                   0   \n",
      "2              night  holiday                     0                   0   \n",
      "3              night  holiday                     0                   0   \n",
      "4              night  holiday                     0                   0   \n",
      "\n",
      "   rain_rush_hour  weather_distance peak_hour_distance  \n",
      "0               0              0.97                0.0  \n",
      "1               0              1.10                0.0  \n",
      "2               0              2.51                0.0  \n",
      "3               0              1.90                0.0  \n",
      "4               0              1.43                0.0  \n",
      "\n",
      "[5 rows x 54 columns]\n",
      "\n",
      " Feature engineering completed successfully!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ----------------------------------------------------------------------\n",
    "# 0. PATH HANDLING\n",
    "# ----------------------------------------------------------------------\n",
    "def safe_path(preferred, fallback):\n",
    "    try:\n",
    "        os.makedirs(os.path.dirname(preferred), exist_ok=True)\n",
    "        return preferred\n",
    "    except Exception:\n",
    "        os.makedirs(os.path.dirname(fallback), exist_ok=True)\n",
    "        return fallback\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "# 0. PATHS \n",
    "# ----------------------------------------------------------------------\n",
    "MERGED_PATH       = \"../data/processed/taxi_weather_zones_merged_2023_sample.parquet\"\n",
    "ENGINEERED_OUT    = \"../data/processed/engineered_features_2023_sample.parquet\"\n",
    "FEATURE_LIST_OUT  = \"../data/processed/feature_list_sample.txt\"\n",
    "FEATURE_STATS_OUT = \"../data/processed/feature_statistics_sample.csv\"\n",
    "\n",
    "os.makedirs(\"../data/processed\", exist_ok=True)\n",
    "\n",
    "print(\"Merged input      :\", MERGED_PATH)\n",
    "print(\"Engineered output :\", ENGINEERED_OUT)\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "# 1. LOAD MERGED DATASET\n",
    "# ----------------------------------------------------------------------\n",
    "df = pd.read_parquet(MERGED_PATH)\n",
    "\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "# 1. LOAD MERGED DATASET\n",
    "# ----------------------------------------------------------------------\n",
    "df = pd.read_parquet(MERGED_PATH)\n",
    "\n",
    "print(\"\\n=== Loaded merged dataset ===\")\n",
    "print(df.shape)\n",
    "print(df.head())\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "# 2. TEMPORAL FEATURES\n",
    "# ----------------------------------------------------------------------\n",
    "dt = df[\"tpep_pickup_datetime\"]\n",
    "\n",
    "df[\"hour\"] = dt.dt.hour\n",
    "df[\"day_of_week\"] = dt.dt.weekday  # 0 = Monday\n",
    "df[\"is_weekend\"] = df[\"day_of_week\"].isin([5, 6]).astype(int)\n",
    "df[\"month\"] = dt.dt.month\n",
    "df[\"day_of_month\"] = dt.dt.day\n",
    "df[\"week_of_year\"] = dt.dt.isocalendar().week.astype(int)\n",
    "df[\"quarter\"] = dt.dt.quarter\n",
    "\n",
    "# US Holiday List \n",
    "us_holidays = {\n",
    "    \"2023-01-01\", \"2023-07-04\", \"2023-12-25\", \"2023-11-23\",\n",
    "    \"2023-05-29\", \"2023-09-04\", \"2023-11-11\"\n",
    "}\n",
    "df[\"is_holiday\"] = df[\"pickup_date\"].astype(str).isin(us_holidays).astype(int)\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "# 3. TRIP-BASED FEATURES\n",
    "# ----------------------------------------------------------------------\n",
    "df[\"tpep_dropoff_datetime\"] = pd.to_datetime(df[\"tpep_dropoff_datetime\"], errors=\"coerce\")\n",
    "\n",
    "df[\"trip_duration_minutes\"] = (\n",
    "    (df[\"tpep_dropoff_datetime\"] - df[\"tpep_pickup_datetime\"]).dt.total_seconds() / 60\n",
    ")\n",
    "\n",
    "df[\"avg_speed_mph\"] = df[\"trip_distance\"] / (df[\"trip_duration_minutes\"] / 60)\n",
    "df[\"fare_per_mile\"] = df[\"fare_amount\"] / df[\"trip_distance\"]\n",
    "df[\"fare_per_minute\"] = df[\"fare_amount\"] / df[\"trip_duration_minutes\"]\n",
    "df[\"distance_squared\"] = df[\"trip_distance\"] ** 2\n",
    "df[\"duration_squared\"] = df[\"trip_duration_minutes\"] ** 2\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "# 4. WEATHER FEATURES\n",
    "# ----------------------------------------------------------------------\n",
    "df[\"temp_fahrenheit\"] = df[\"temperature_avg\"]\n",
    "\n",
    "df[\"is_raining\"] = (df[\"precipitation\"] > 0).astype(int)\n",
    "\n",
    "def temp_category(t):\n",
    "    if pd.isna(t): return np.nan\n",
    "    if t < 32: return \"cold\"\n",
    "    if t > 75: return \"hot\"\n",
    "    return \"moderate\"\n",
    "\n",
    "df[\"temp_category\"] = df[\"temp_fahrenheit\"].apply(temp_category)\n",
    "\n",
    "# Monthly average temp\n",
    "monthly_mean_temp = df.groupby(\"month\")[\"temp_fahrenheit\"].transform(\"mean\")\n",
    "df[\"temp_deviation\"] = df[\"temp_fahrenheit\"] - monthly_mean_temp\n",
    "\n",
    "df[\"extreme_weather\"] = (\n",
    "    (df[\"is_raining\"] == 1) |\n",
    "    (df[\"temp_fahrenheit\"] < 20) |\n",
    "    (df[\"temp_fahrenheit\"] > 90)\n",
    ").astype(int)\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "# 5. SPATIAL FEATURES\n",
    "# ----------------------------------------------------------------------\n",
    "df[\"same_borough\"] = (df[\"pickup_borough\"] == df[\"dropoff_borough\"]).astype(int)\n",
    "\n",
    "df[\"zone_pair_encoded\"] = (\n",
    "    df[\"pickup_zone\"].astype(str) + \"_\" +\n",
    "    df[\"dropoff_zone\"].astype(str)\n",
    ")\n",
    "\n",
    "# Pickup density (per zone per hour)\n",
    "df[\"pickup_density\"] = (\n",
    "    df.groupby([\"pickup_zone\", \"hour\"])[\"pickup_zone\"].transform(\"count\")\n",
    ")\n",
    "\n",
    "# Traffic volume category (from congestion surcharge)\n",
    "def traffic_cat(c):\n",
    "    if c == 0: return \"low\"\n",
    "    if c == 2.50: return \"medium\"\n",
    "    if c == 2.75: return \"high\"\n",
    "    return \"other\"\n",
    "\n",
    "if \"congestion_surcharge\" in df.columns:\n",
    "    df[\"traffic_volume_category\"] = df[\"congestion_surcharge\"].apply(traffic_cat)\n",
    "else:\n",
    "    df[\"traffic_volume_category\"] = \"unknown\"\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "# 6. DEMAND-BASED FEATURES\n",
    "# ----------------------------------------------------------------------\n",
    "df[\"hourly_pickup_count\"] = df.groupby([\"pickup_date\", \"hour\"])[\"pickup_date\"].transform(\"count\")\n",
    "\n",
    "df[\"zone_hourly_pickup_count\"] = df.groupby(\n",
    "    [\"pickup_zone\", \"pickup_date\", \"hour\"]\n",
    ")[\"pickup_zone\"].transform(\"count\")\n",
    "\n",
    "df[\"is_peak_hour\"] = (\n",
    "    ((df[\"hour\"].between(7, 10)) | (df[\"hour\"].between(17, 20))) &\n",
    "    (df[\"is_weekend\"] == 0)\n",
    ").astype(int)\n",
    "\n",
    "df[\"is_late_night\"] = df[\"hour\"].between(0, 5).astype(int)\n",
    "\n",
    "avg_hourly = df.groupby(\"hour\")[\"hourly_pickup_count\"].transform(\"mean\")\n",
    "df[\"surge_likelihood\"] = df[\"hourly_pickup_count\"] / avg_hourly\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "# 7. DERIVED FEATURES\n",
    "# ----------------------------------------------------------------------\n",
    "df[\"fare_per_distance_per_minute\"] = df[\"fare_amount\"] / (\n",
    "    df[\"trip_distance\"] * df[\"trip_duration_minutes\"]\n",
    ")\n",
    "\n",
    "df[\"trip_complexity\"] = (\n",
    "    df[\"trip_distance\"] * df[\"avg_speed_mph\"] * df[\"is_raining\"]\n",
    ")\n",
    "\n",
    "def time_of_day(h):\n",
    "    if 5 <= h < 12: return \"morning\"\n",
    "    if 12 <= h < 17: return \"afternoon\"\n",
    "    if 17 <= h < 21: return \"evening\"\n",
    "    return \"night\"\n",
    "\n",
    "df[\"time_of_day_factor\"] = df[\"hour\"].apply(time_of_day)\n",
    "\n",
    "def day_type(row):\n",
    "    if row[\"is_holiday\"] == 1: return \"holiday\"\n",
    "    if row[\"is_weekend\"] == 1: return \"weekend\"\n",
    "    return \"weekday\"\n",
    "\n",
    "df[\"day_type\"] = df.apply(day_type, axis=1)\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "# 8. OUTLIER FLAGS\n",
    "# ----------------------------------------------------------------------\n",
    "fare_95 = df[\"fare_amount\"].quantile(0.95)\n",
    "dist_95 = df[\"trip_distance\"].quantile(0.95)\n",
    "\n",
    "df[\"extreme_fare_flag\"] = (df[\"fare_amount\"] > fare_95).astype(int)\n",
    "df[\"extreme_distance_flag\"] = (df[\"trip_distance\"] > dist_95).astype(int)\n",
    "df[\"zero_distance_flag\"] = (df[\"trip_distance\"] <= 0).astype(int)\n",
    "df[\"zero_fare_flag\"] = (df[\"fare_amount\"] <= 0).astype(int)\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "# 9. INTERACTION FEATURES\n",
    "# ----------------------------------------------------------------------\n",
    "df[\"rain_rush_hour\"] = df[\"is_raining\"] * df[\"is_peak_hour\"]\n",
    "df[\"weather_distance\"] = df[\"extreme_weather\"] * df[\"trip_distance\"]\n",
    "df[\"peak_hour_distance\"] = df[\"is_peak_hour\"] * df[\"trip_distance\"]\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "# 10. CLEANING & VALIDATION\n",
    "# ----------------------------------------------------------------------\n",
    "df = df[\n",
    "    (df[\"trip_distance\"] > 0) &\n",
    "    (df[\"fare_amount\"] > 0) &\n",
    "    (df[\"trip_duration_minutes\"] > 0)\n",
    "].copy()\n",
    "\n",
    "df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "\n",
    "for col in df.select_dtypes(include=\"number\").columns:\n",
    "    df[col].fillna(df[col].mean(), inplace=True)\n",
    "\n",
    "for col in df.select_dtypes(include=\"object\").columns:\n",
    "    df[col].fillna(df[col].mode()[0], inplace=True)\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "# 11. FEATURE SELECTION & PREPARATION\n",
    "# ----------------------------------------------------------------------\n",
    "\n",
    "\n",
    "# drop_cols = [\n",
    "#     \"tpep_pickup_datetime\", \"tpep_dropoff_datetime\"\n",
    "# ]\n",
    "# df.drop(columns=[c for c in drop_cols if c in df.columns], inplace=True)\n",
    "\n",
    "# numerical_features = df.select_dtypes(include=[\"int64\", \"float64\"]).columns.tolist()\n",
    "# categorical_features = df.select_dtypes(include=[\"object\", \"category\"]).columns.tolist()\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "# 11. REMOVE TARGET-LEAKING FEATURES FROM MODELING DATA\n",
    "# ----------------------------------------------------------------------\n",
    "# Features derived directly from the target `fare_amount`\n",
    "leaky_fare_features = [\n",
    "    \"fare_per_mile\",\n",
    "    \"fare_per_minute\",\n",
    "    \"fare_per_distance_per_minute\",\n",
    "    \"extreme_fare_flag\",\n",
    "    \"zero_fare_flag\",\n",
    "]\n",
    "\n",
    "# Financial components that let the model reconstruct the fare/total\n",
    "leaky_financial_features = [\n",
    "    \"total_amount\",\n",
    "    \"tip_amount\",\n",
    "    \"tolls_amount\",\n",
    "    \"mta_tax\",\n",
    "    \"extra\",\n",
    "    \"congestion_surcharge\",\n",
    "    \"airport_fee\",\n",
    "]\n",
    "\n",
    "leaky_features = leaky_fare_features + leaky_financial_features\n",
    "\n",
    "existing_leaky = [c for c in leaky_features if c in df.columns]\n",
    "if existing_leaky:\n",
    "    print(\"\\nDropping target/financial-leaking features from engineered dataset used for modeling:\")\n",
    "    print(existing_leaky)\n",
    "    df = df.drop(columns=existing_leaky)\n",
    "else:\n",
    "    print(\"\\nNo target/financial-leaking features found to drop.\")\n",
    "\n",
    "# Now recompute feature type lists AFTER dropping\n",
    "numerical_features = df.select_dtypes(include=[\"int64\", \"float64\"]).columns.tolist()\n",
    "categorical_features = df.select_dtypes(include=[\"object\", \"category\"]).columns.tolist()\n",
    "\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "# 12. SAVE OUTPUTS\n",
    "# ----------------------------------------------------------------------\n",
    "df.to_parquet(ENGINEERED_OUT, index=False)\n",
    "print(\"\\n Saved engineered dataset to:\", ENGINEERED_OUT)\n",
    "\n",
    "# Feature list\n",
    "with open(FEATURE_LIST_OUT, \"w\") as f:\n",
    "    for col in df.columns:\n",
    "        dtype = \"numerical\" if col in numerical_features else \"categorical\"\n",
    "        f.write(f\"{col} | {dtype}\\n\")\n",
    "\n",
    "print(\" Saved feature list:\", FEATURE_LIST_OUT)\n",
    "\n",
    "# Feature statistics\n",
    "stats = df[numerical_features].describe().T\n",
    "stats.to_csv(FEATURE_STATS_OUT)\n",
    "print(\" Saved feature statistics:\", FEATURE_STATS_OUT)\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "# 13. SUMMARY OUTPUT\n",
    "# ----------------------------------------------------------------------\n",
    "print(\"\\n=== FINAL SUMMARY ===\")\n",
    "print(\"Total rows  :\", len(df))\n",
    "print(\"Total cols  :\", len(df.columns))\n",
    "print(\"Numerical   :\", len(numerical_features))\n",
    "print(\"Categorical :\", len(categorical_features))\n",
    "\n",
    "print(\"\\nMissing values per feature:\")\n",
    "print(df.isna().sum().sort_values(ascending=False).head(20))\n",
    "\n",
    "print(\"\\nSample of engineered data:\")\n",
    "print(df.head())\n",
    "\n",
    "print(\"\\n Feature engineering completed successfully!\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
